{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "import transform, numpy as np, vgg, pdb, os\n",
    "import scipy.misc\n",
    "import tensorflow as tf\n",
    "from utils import save_img, get_img, exists, list_files\n",
    "from argparse import ArgumentParser\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import json\n",
    "import subprocess\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "DEVICE = '/gpu:0'\n",
    "\n",
    "\n",
    "def from_pipe(opts):\n",
    "    command = [\"ffprobe\",\n",
    "               '-v', \"quiet\",\n",
    "               '-print_format', 'json',\n",
    "               '-show_streams', opts.in_path]\n",
    "\n",
    "    info = json.loads(str(subprocess.check_output(command), encoding=\"utf8\"))\n",
    "    width = int(info[\"streams\"][0][\"width\"])\n",
    "    height = int(info[\"streams\"][0][\"height\"])\n",
    "    fps = round(eval(info[\"streams\"][0][\"r_frame_rate\"]))\n",
    "\n",
    "    command = [\"ffmpeg\",\n",
    "               '-loglevel', \"quiet\",\n",
    "               '-i', opts.in_path,\n",
    "               '-f', 'image2pipe',\n",
    "               '-pix_fmt', 'rgb24',\n",
    "               '-vcodec', 'rawvideo', '-']\n",
    "\n",
    "    pipe_in = subprocess.Popen(command, stdout=subprocess.PIPE, bufsize=10 ** 9, stdin=None, stderr=None)\n",
    "\n",
    "    command = [\"ffmpeg\",\n",
    "               '-loglevel', \"info\",\n",
    "               '-y',  # (optional) overwrite output file if it exists\n",
    "               '-f', 'rawvideo',\n",
    "               '-vcodec', 'rawvideo',\n",
    "               '-s', str(width) + 'x' + str(height),  # size of one frame\n",
    "               '-pix_fmt', 'rgb24',\n",
    "               '-r', str(fps),  # frames per second\n",
    "               '-i', '-',  # The imput comes from a pipe\n",
    "               '-an',  # Tells FFMPEG not to expect any audio\n",
    "               '-c:v', 'libx264',\n",
    "               '-preset', 'slow',\n",
    "               '-crf', '18',\n",
    "               opts.out]\n",
    "\n",
    "    pipe_out = subprocess.Popen(command, stdin=subprocess.PIPE, stdout=None, stderr=None)\n",
    "    g = tf.Graph()\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "\n",
    "    with g.as_default(), g.device(opts.device), \\\n",
    "         tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (opts.batch_size, height, width, 3)\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(opts.checkpoint):\n",
    "            ckpt = tf.train.get_checkpoint_state(opts.checkpoint)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, opts.checkpoint)\n",
    "\n",
    "        X = np.zeros(batch_shape, dtype=np.float32)\n",
    "        nbytes = 3 * width * height\n",
    "        read_input = True\n",
    "        last = False\n",
    "\n",
    "        while read_input:\n",
    "            count = 0\n",
    "            while count < opts.batch_size:\n",
    "                raw_image = pipe_in.stdout.read(width * height * 3)\n",
    "\n",
    "                if len(raw_image) != nbytes:\n",
    "                    if count == 0:\n",
    "                        read_input = False\n",
    "                    else:\n",
    "                        last = True\n",
    "                        X = X[:count]\n",
    "                        batch_shape = (count, height, width, 3)\n",
    "                        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                                     name='img_placeholder')\n",
    "                        preds = transform.net(img_placeholder)\n",
    "                    break\n",
    "\n",
    "                image = numpy.fromstring(raw_image, dtype='uint8')\n",
    "                image = image.reshape((height, width, 3))\n",
    "                X[count] = image\n",
    "                count += 1\n",
    "\n",
    "            if read_input:\n",
    "                if last:\n",
    "                    read_input = False\n",
    "                _preds = sess.run(preds, feed_dict={img_placeholder: X})\n",
    "\n",
    "                for i in range(0, batch_shape[0]):\n",
    "                    img = np.clip(_preds[i], 0, 255).astype(np.uint8)\n",
    "                    try:\n",
    "                        pipe_out.stdin.write(img)\n",
    "                    except IOError as err:\n",
    "                        ffmpeg_error = pipe_out.stderr.read()\n",
    "                        error = (str(err) + (\"\\n\\nFFMPEG encountered\"\n",
    "                                             \"the following error while writing file:\"\n",
    "                                             \"\\n\\n %s\" % ffmpeg_error))\n",
    "                        read_input = False\n",
    "                        print(error)\n",
    "        pipe_out.terminate()\n",
    "        pipe_in.terminate()\n",
    "        pipe_out.stdin.close()\n",
    "        pipe_in.stdout.close()\n",
    "        del pipe_in\n",
    "        del pipe_out\n",
    "\n",
    "# get img_shape\n",
    "def ffwd(data_in, paths_out, checkpoint_dir, device_t='/gpu:0', batch_size=4):\n",
    "    assert len(paths_out) > 0\n",
    "    is_paths = type(data_in[0]) == str\n",
    "    if is_paths:\n",
    "        assert len(data_in) == len(paths_out)\n",
    "        img_shape = get_img(data_in[0]).shape\n",
    "    else:\n",
    "        assert data_in.size[0] == len(paths_out)\n",
    "        img_shape = X[0].shape\n",
    "\n",
    "    g = tf.Graph()\n",
    "    batch_size = min(len(paths_out), batch_size)\n",
    "    curr_num = 0\n",
    "    soft_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    soft_config.gpu_options.allow_growth = True\n",
    "    with g.as_default(), g.device(device_t), \\\n",
    "            tf.Session(config=soft_config) as sess:\n",
    "        batch_shape = (batch_size,) + img_shape\n",
    "        img_placeholder = tf.placeholder(tf.float32, shape=batch_shape,\n",
    "                                         name='img_placeholder')\n",
    "\n",
    "        preds = transform.net(img_placeholder)\n",
    "        saver = tf.train.Saver()\n",
    "        if os.path.isdir(checkpoint_dir):\n",
    "            ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                raise Exception(\"No checkpoint found...\")\n",
    "        else:\n",
    "            saver.restore(sess, checkpoint_dir)\n",
    "\n",
    "        num_iters = int(len(paths_out)/batch_size)\n",
    "        for i in range(num_iters):\n",
    "            pos = i * batch_size\n",
    "            curr_batch_out = paths_out[pos:pos+batch_size]\n",
    "            if is_paths:\n",
    "                curr_batch_in = data_in[pos:pos+batch_size]\n",
    "                X = np.zeros(batch_shape, dtype=np.float32)\n",
    "                for j, path_in in enumerate(curr_batch_in):\n",
    "                    img = get_img(path_in)\n",
    "                    assert img.shape == img_shape, \\\n",
    "                        'Images have different dimensions. ' +  \\\n",
    "                        'Resize images or use --allow-different-dimensions.'\n",
    "                    X[j] = img\n",
    "            else:\n",
    "                X = data_in[pos:pos+batch_size]\n",
    "\n",
    "            _preds = sess.run(preds, feed_dict={img_placeholder:X})\n",
    "            for j, path_out in enumerate(curr_batch_out):\n",
    "                save_img(path_out, _preds[j])\n",
    "                \n",
    "        remaining_in = data_in[num_iters*batch_size:]\n",
    "        remaining_out = paths_out[num_iters*batch_size:]\n",
    "    if len(remaining_in) > 0:\n",
    "        ffwd(remaining_in, remaining_out, checkpoint_dir, \n",
    "            device_t=device_t, batch_size=1)\n",
    "\n",
    "def ffwd_to_img(in_path, out_path, checkpoint_dir, device='/cpu:0'):\n",
    "    paths_in, paths_out = [in_path], [out_path]\n",
    "    ffwd(paths_in, paths_out, checkpoint_dir, batch_size=1, device_t=device)\n",
    "\n",
    "def ffwd_different_dimensions(in_path, out_path, checkpoint_dir, \n",
    "            device_t=DEVICE, batch_size=4):\n",
    "    in_path_of_shape = defaultdict(list)\n",
    "    out_path_of_shape = defaultdict(list)\n",
    "    for i in range(len(in_path)):\n",
    "        in_image = in_path[i]\n",
    "        out_image = out_path[i]\n",
    "        shape = \"%dx%dx%d\" % get_img(in_image).shape\n",
    "        in_path_of_shape[shape].append(in_image)\n",
    "        out_path_of_shape[shape].append(out_image)\n",
    "    for shape in in_path_of_shape:\n",
    "        print('Processing images of shape %s' % shape)\n",
    "        ffwd(in_path_of_shape[shape], out_path_of_shape[shape], \n",
    "            checkpoint_dir, device_t, batch_size)\n",
    "\n",
    "def build_parser():\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--checkpoint', type=str,\n",
    "                        dest='checkpoint_dir',\n",
    "                        help='dir or .ckpt file to load checkpoint from',\n",
    "                        metavar='CHECKPOINT', required=True)\n",
    "\n",
    "    parser.add_argument('--in-path', type=str,\n",
    "                        dest='in_path',help='dir or file to transform',\n",
    "                        metavar='IN_PATH', required=True)\n",
    "\n",
    "    help_out = 'destination (dir or file) of transformed file or files'\n",
    "    parser.add_argument('--out-path', type=str,\n",
    "                        dest='out_path', help=help_out, metavar='OUT_PATH',\n",
    "                        required=True)\n",
    "\n",
    "    parser.add_argument('--device', type=str,\n",
    "                        dest='device',help='device to perform compute on',\n",
    "                        metavar='DEVICE', default=DEVICE)\n",
    "\n",
    "    parser.add_argument('--batch-size', type=int,\n",
    "                        dest='batch_size',help='batch size for feedforwarding',\n",
    "                        metavar='BATCH_SIZE', default=BATCH_SIZE)\n",
    "\n",
    "    parser.add_argument('--allow-different-dimensions', action='store_true',\n",
    "                        dest='allow_different_dimensions', \n",
    "                        help='allow different image dimensions')\n",
    "\n",
    "    return parser\n",
    "\n",
    "def check_opts(opts):\n",
    "    exists(opts.checkpoint_dir, 'Checkpoint not found!')\n",
    "    exists(opts.in_path, 'In path not found!')\n",
    "    if os.path.isdir(opts.out_path):\n",
    "        exists(opts.out_path, 'out dir not found!')\n",
    "        assert opts.batch_size > 0\n",
    "\n",
    "def main():\n",
    "    parser = build_parser()\n",
    "    opts = parser.parse_args()\n",
    "    check_opts(opts)\n",
    "\n",
    "\n",
    "    if not os.path.isdir(opts.in_path):\n",
    "        if os.path.exists(opts.out_path) and os.path.isdir(opts.out_path):\n",
    "            out_path = \\\n",
    "                    os.path.join(opts.out_path,os.path.basename(opts.in_path))\n",
    "        else:\n",
    "            out_path = opts.out_path\n",
    "\n",
    "        ffwd_to_img(opts.in_path, out_path, opts.checkpoint_dir,\n",
    "                    device=opts.device)\n",
    "    else:\n",
    "        files = list_files(opts.in_path)\n",
    "        full_in = [os.path.join(opts.in_path,x) for x in files]\n",
    "        full_out = [os.path.join(opts.out_path,x) for x in files]\n",
    "        if opts.allow_different_dimensions:\n",
    "            ffwd_different_dimensions(full_in, full_out, opts.checkpoint_dir, \n",
    "                    device_t=opts.device, batch_size=opts.batch_size)\n",
    "        else :\n",
    "            ffwd(full_in, full_out, opts.checkpoint_dir, device_t=opts.device,\n",
    "                    batch_size=opts.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def me_main(opts):\n",
    "    if not os.path.isdir(opts.in_path):\n",
    "        if os.path.exists(opts.out_path) and os.path.isdir(opts.out_path):\n",
    "            out_path = \\\n",
    "                    os.path.join(opts.out_path,os.path.basename(opts.in_path))\n",
    "        else:\n",
    "            out_path = opts.out_path\n",
    "\n",
    "        ffwd_to_img(opts.in_path, out_path, opts.checkpoint_dir,\n",
    "                    device=opts.device)\n",
    "    else:\n",
    "        files = list_files(opts.in_path)\n",
    "        full_in = [os.path.join(opts.in_path,x) for x in files]\n",
    "        full_out = [os.path.join(opts.out_path,x) for x in files]\n",
    "        if opts.allow_different_dimensions:\n",
    "            ffwd_different_dimensions(full_in, full_out, opts.checkpoint_dir, \n",
    "                    device_t=opts.device, batch_size=opts.batch_size)\n",
    "        else :\n",
    "            ffwd(full_in, full_out, opts.checkpoint_dir, device_t=opts.device,\n",
    "                    batch_size=opts.batch_size)\n",
    "            \n",
    "\n",
    "class options:\n",
    "    checkpoint_dir = \"models/wave.ckpt\"\n",
    "    in_path = \"images/content\"\n",
    "    out_path = \"images/result\"\n",
    "    batch_size = 4\n",
    "    device = \"/cpu:0\"\n",
    "    allow_different_dimensions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images of shape 474x712x3\n",
      "INFO:tensorflow:Restoring parameters from models/wave.ckpt\n",
      "Processing images of shape 679x1024x3\n",
      "INFO:tensorflow:Restoring parameters from models/wave.ckpt\n"
     ]
    }
   ],
   "source": [
    "opts = options()\n",
    "me_main(opts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
